{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c387c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain.chains import LLMChain, HypotheticalDocumentEmbedder\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "860464d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emolt\\AppData\\Local\\Temp\\ipykernel_2556\\3471671973.py:7: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=local_llm, base_url=url_llm, temperature=0)\n"
     ]
    }
   ],
   "source": [
    "local_llm = \"llama3.2:latest\"\n",
    "#url_llm = \"http://172.17.30.133:11434\" # ordenados con 2 gpus\n",
    "#url_llm = \"http://172.17.30.172:11434\" #COMPUTACION\n",
    "url_llm = \"http://localhost:11434\"\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=local_llm, base_url=url_llm, temperature=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39232167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List, Optional\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "class StructuredTXTDirectoryLoader(BaseLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        directory_path: str,\n",
    "        metadata_keys: Optional[List[str]] = None,\n",
    "        encoding: Optional[str] = \"utf-8\"\n",
    "    ):\n",
    "        self.directory_path = directory_path\n",
    "        self.metadata_keys = metadata_keys or []\n",
    "        self.encoding = encoding\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        docs = []\n",
    "\n",
    "        for filename in os.listdir(self.directory_path):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                file_path = os.path.join(self.directory_path, filename)\n",
    "                with open(file_path, \"r\", encoding=self.encoding) as f:\n",
    "                    content = f.read()\n",
    "\n",
    "                metadata = {\"source\": filename}\n",
    "\n",
    "                for key in self.metadata_keys:\n",
    "                    # Busca líneas como \"key: valor\"\n",
    "                    pattern = rf\"{re.escape(key)}\\s*:\\s*(.+)\"\n",
    "                    match = re.search(pattern, content, re.IGNORECASE)\n",
    "                    if match:\n",
    "                        metadata[key] = match.group(1).strip()\n",
    "\n",
    "                doc = Document(page_content=content, metadata=metadata)\n",
    "                docs.append(doc)\n",
    "\n",
    "        return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dc6e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_columns = [\n",
    "    \"row\", \"grant agreement\", \"project acronym\", \"organisation PIC\", \"organisation name\",\n",
    "    \"Small or Medium-sized Enterprise\", \"organisation activity type\", \"organisation country\",\n",
    "    \"organisation role\", \"funding for the organisation\", \"organisation total participation cost\",\n",
    "    \"project title\", \"project total cost\", \"funding for the project\", \"master call\",\n",
    "    \"subcall\", \"type of proposal\", \"project legal basis\", \"project topic\"\n",
    "]\n",
    "\n",
    "loader = StructuredTXTDirectoryLoader(\n",
    "    directory_path=r\"C:\\Users\\emolt\\OneDrive - UMH\\MASTER\\TFM\\projects_plain_text\",\n",
    "    metadata_keys=metadata_columns,\n",
    "    encoding=\"latin1\"\n",
    ")\n",
    "\n",
    "raw_documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525c5052",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Número de documentos originales: {len(raw_documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cc55e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = \"What is the objective of the project with grant agreement 740934?\"\n",
    "query_2 = \"What is the total cost of the project with the acronym HYPERGRYD?\"\n",
    "query_3 = \"How much funding was allocated for the project titled Transforming Research through Innovative Practices for Linked interdisciplinary Exploration?\"\n",
    "query_4 = \"Which organisation played the role of coordinator in the grant agreement 777998?\"\n",
    "query_5 = \"What topic does the project with the acronym INTERRFACE belong to?\"\n",
    "query_6 = \"What legal basis was the project titled European Joint Programme on Radioactive Waste Management framed within?\"\n",
    "query_7 = \"What type of proposal was the grant agreement 814416?\"\n",
    "query_8 = \"To which master call was the project with the acronym G9NIGHT submitted?\"\n",
    "query_9 = \"To which sub call was the project titled Electron Nanocrystallography submitted?\"\n",
    "query_10 = \"Provide the grant agreement of 1 project which objective is related to artificial intelligence.\"\n",
    "query_11 = \"Provide the acronym of 1 project which objective is related to robotics.\"\n",
    "query_12 = \"Provide the title of 1 project which objective is related to geolocation.\"\n",
    "query_13 = \"Provide the objective of 1 project related to digital twin.\"\n",
    "query_14 = \"Provide the objective of 3 different projects related to corrosion.\"\n",
    "query_15 = \"Provide the title of 3 different projects which objective is related to offshore structures.\"\n",
    "query_16 = \"Provide the acronym of 3 different projects which objective is related to materials engineering.\"\n",
    "query_17 = \"Provide the grant agreement of 3 different projects which objective is related to nanocomposites.\"\n",
    "query_18 = \"Provide the name of an organisation that has participated in projects which objective is related to artificial intelligence.\"\n",
    "query_19 = \"Provide the name of an organisation which activity type is PRC and that has participated in projects which objective is related to robotics.\"\n",
    "query_20 = \"Provide the PIC of an organisation that is a small or medium enterprise and has participated in projects which objective is related to geolocation.\"\n",
    "query_21 = \"Provide the name of an organisation that has played the role of coordinator in projects which objective is related to digital twin.\"\n",
    "query_22 = \"Provide the PIC of a Spanish organisation that has participated in projects which objective is related to corrosion.\"\n",
    "query_23 = \"Provide the name of an european organisation that has participated in projects which objective is related to offshore structures.\"\n",
    "query_24 = \"Provide the PIC of an european small or medium enterprise that has participated in projects which objective is related to materials engineering.\"\n",
    "query_25 = \"Provide the name of an european small or medium enterprise that has played the role of coordinator in projects which objective is related to nanocomposites.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffcb18d",
   "metadata": {},
   "source": [
    "## EXP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1195dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=800)\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76880c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de chunks generados: 513923\n"
     ]
    }
   ],
   "source": [
    "print(f\"Número de chunks generados: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d56ffd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emolt\\AppData\\Local\\Temp\\ipykernel_2556\\2374641863.py:7: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  emb = HuggingFaceBgeEmbeddings(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs)\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"sentence-transformers/paraphrase-MiniLM-L6-v2\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "\n",
    "emb = HuggingFaceBgeEmbeddings(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5a06f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "vectorstore_7_txt = FAISS.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=emb  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "606c3771",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_7_txt.save_local(\"faiss_index_proyectos_7_txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c2f250",
   "metadata": {},
   "source": [
    "## EXP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c20fb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=400)\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc58f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"sentence-transformers/paraphrase-MiniLM-L6-v2\"\n",
    "model_kwargs = {\"device\": \"cpu\"} # Al no tener NVIDIA es necesario cambiarlo model_kwargs = {'device': 'cuda:0'}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "\n",
    "emb = HuggingFaceBgeEmbeddings(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e911f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS  # o Chroma, Pinecone, etc.\n",
    "# Suponiendo que `documents` es una lista de Document objects con .page_content y .metadata\n",
    "vectorstore_8_txt = FAISS.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=emb  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a403049",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_8_txt.save_local(\"faiss_index_proyectos_8_txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb1a908",
   "metadata": {},
   "source": [
    "## EXP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7389dd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b485ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    doc.page_content = f\"passage: {doc.page_content}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e91999a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emolt\\AppData\\Local\\Temp\\ipykernel_11668\\2086778471.py:6: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  emb_9 = HuggingFaceBgeEmbeddings(model_name=model_name_9,model_kwargs=model_kwargs_9,encode_kwargs=encode_kwargs_9)\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "model_name_9 = \"intfloat/e5-small-v2\"\n",
    "model_kwargs_9 = {\"device\": \"cpu\"}\n",
    "encode_kwargs_9={\"normalize_embeddings\": True, \"batch_size\": 32}\n",
    "\n",
    "emb_9 = HuggingFaceBgeEmbeddings(model_name=model_name_9,model_kwargs=model_kwargs_9,encode_kwargs=encode_kwargs_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3be54a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS  # o Chroma, Pinecone, etc.\n",
    "# Suponiendo que `documents` es una lista de Document objects con .page_content y .metadata\n",
    "vectorstore_9_txt = FAISS.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=emb_9  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81be4d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_9_txt.save_local(\"faiss_index_proyectos_9_txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb45b6c4",
   "metadata": {},
   "source": [
    "## EXP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2fc462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=800)\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa05cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    doc.page_content = f\"passage: {doc.page_content}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "962db8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS  # o Chroma, Pinecone, etc.\n",
    "# Suponiendo que `documents` es una lista de Document objects con .page_content y .metadata\n",
    "vectorstore_10_txt = FAISS.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=emb_9  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c05a8e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_10_txt.save_local(\"faiss_index_proyectos_10_txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 REAL",
   "language": "python",
   "name": "py310real"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
