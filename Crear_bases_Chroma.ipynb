{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a0550f1-c2c5-41ef-bc3d-f9845c3c3ede",
   "metadata": {},
   "source": [
    "# Crear bases de vectores de Chroma: 1, 2 ,3, 4, 5 y 6\n",
    "## Cada vez que se vaya a crear una nueva base de vectores, es mejor reiniciar el kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8adf74b-5847-419a-bed4-90e52ddb41b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1647cf36-fc50-4b12-952e-09f7188466d0",
   "metadata": {},
   "source": [
    "### Se cargan los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b10498-08f2-4a34-9f4c-3d4bb9e88a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA CREAR METADATOS\n",
    "import csv\n",
    "from typing import Dict, List, Optional\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "class CSVLoader(BaseLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_path: str,\n",
    "        source_column: Optional[str] = None,\n",
    "        metadata_columns: Optional[List[str]] = None,\n",
    "        csv_args: Optional[Dict] = None,\n",
    "        encoding: Optional[str] = None,\n",
    "    ):\n",
    "        self.file_path = file_path\n",
    "        self.source_column = source_column\n",
    "        self.encoding = encoding\n",
    "        self.csv_args = csv_args or {}\n",
    "        self.metadata_columns = metadata_columns or []\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        docs = []\n",
    "        with open(self.file_path, newline=\"\", encoding=self.encoding) as csvfile:\n",
    "            csv_reader = csv.DictReader(csvfile, **self.csv_args)\n",
    "            for i, row in enumerate(csv_reader):\n",
    "                metadata = {\"row\": i}\n",
    "                for col in self.metadata_columns:\n",
    "                    if col in row:\n",
    "                        metadata[col] = row[col].strip()\n",
    "                content = []\n",
    "                for k, v in row.items():\n",
    "                    if k != self.source_column and k not in self.metadata_columns:\n",
    "                        content.append(f\"{k.strip()}: {v.strip()}\")\n",
    "                doc_content = \"\\n\".join(content)\n",
    "                doc = Document(page_content=doc_content, metadata=metadata)\n",
    "                docs.append(doc)\n",
    "\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd9be0d5-4f73-4891-b62a-6c55eed986aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_columns = [\"row\"]\n",
    "\n",
    "# Instancia el CSVLoader con el archivo CSV y las columnas de metadatos\n",
    "loader = CSVLoader(\n",
    "    file_path=\"cordis_data_processed_29052024.csv\",\n",
    "    source_column= None,  # Opcional: columna para establecer como origen\n",
    "    metadata_columns=metadata_columns,\n",
    "    encoding=\"latin1\"\n",
    ")\n",
    "\n",
    "# Carga los documentos del CSV\n",
    "raw_documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cf2d66-ac63-42d5-a94a-5645b4ccc1a1",
   "metadata": {},
   "source": [
    "## Chroma_db_1, Chroma_db_2, Chroma_db_3: mismos chunks (1000), distintos embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7422f9a5-e480-4043-af99-c37c087b07a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\" \",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=800,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "all_splits = text_splitter.split_documents(raw_documents)\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9088835-8ff7-4837-9f24-c5bd18a00a9a",
   "metadata": {},
   "source": [
    "### Chroma_db_1: GPT4ALLEmbeddings (22,7M parámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1a7a64-6bc6-4399-8904-92d5af1056de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "\n",
    "emb = GPT4AllEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a9d8d1-a49e-4292-9f69-9a86e5cf3a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para crear la base de vectores\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=emb, persist_directory=\"./chroma_db_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef99217-524e-4ad4-99c8-2a09c1d66903",
   "metadata": {},
   "source": [
    "### Chroma_db_2: bge-large-en (335M parámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76858dc-95b6-4f9f-9d53-5a3c586ff927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE USA UNA DE LAS GPU\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "model_name = \"BAAI/bge-large-en\"\n",
    "model_kwargs = {'device': 'cuda:1'}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "\n",
    "emb = HuggingFaceBgeEmbeddings(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b23f4-8dd2-44e4-ab70-c2425ea71811",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=emb, persist_directory=\"./chroma_db_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4701491f-7ffb-45cf-a70e-58048db97c5f",
   "metadata": {},
   "source": [
    "### Chroma_db_3: all-mpnet-base-v2 (109M parámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487ec048-2dc0-496b-8908-68f03c106fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE USA UNA DE LAS GPU\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "model_name = \"all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cuda:1'}  # specify GPU device\n",
    "\n",
    "emb = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1752b47-cdc0-4d99-8e0c-2bfd9a00b160",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=emb, persist_directory=\"./chroma_db_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff8525f-200b-4e19-9e4a-660bbf523f12",
   "metadata": {},
   "source": [
    "## Chroma_db_4, Chroma_db_5, Chroma_db_5: mismos chunks (500), distintos embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca5a291-529c-4ac9-97d0-d829499abce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4114629"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\" \",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=400,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "all_splits = text_splitter.split_documents(raw_documents)\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7bc438-6003-40c9-ba88-8bc3d3f10e64",
   "metadata": {},
   "source": [
    "### Chroma_db_4: GPT4ALLEmbeddings (22,7M parámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b364b6e-8cd7-4749-a478-bd78da32858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "\n",
    "emb = GPT4AllEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e250c500-16d0-4d7d-a85b-ee93b60b9f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=emb, persist_directory=\"./chroma_db_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ca706e-4404-4ceb-b87b-7c1f2f0d288f",
   "metadata": {},
   "source": [
    "### Chroma_db_5: bge-large-en (335M parámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df2c42c-4bdf-4d47-a2b6-7dc84a9066e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE USA UNA DE LAS GPU\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "model_name = \"BAAI/bge-large-en\"\n",
    "model_kwargs = {'device': 'cuda:1'}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "\n",
    "emb = HuggingFaceBgeEmbeddings(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23cf69a-e116-4699-9418-48269afe2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=emb, persist_directory=\"./chroma_db_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f24610-d466-4cb8-871d-d712d264d194",
   "metadata": {},
   "source": [
    "### Chroma_db_3: all-mpnet-base-v2 (109M parámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9095d19b-e15e-4d05-8eda-a598e76a19df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\miniconda3\\envs\\local_llm\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "C:\\ProgramData\\miniconda3\\envs\\local_llm\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# SE USA UNA DE LAS GPU\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "model_name = \"all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cuda:1'}  # specify GPU device\n",
    "\n",
    "emb = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=emb, persist_directory=\"./chroma_db_6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188c921a-70ff-42bd-b5d9-42318329ddbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
