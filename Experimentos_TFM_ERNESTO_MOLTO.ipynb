{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0254d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain.chains import LLMChain, HypotheticalDocumentEmbedder\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad67c0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emolt\\AppData\\Local\\Temp\\ipykernel_15164\\3005633854.py:6: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=local_llm, base_url=url_llm, temperature=0)\n"
     ]
    }
   ],
   "source": [
    "local_llm = \"llama3.2:latest\"\n",
    "url_llm = \"http://172.17.30.133:11434\" # ordenados con 2 gpus\n",
    "#url_llm = \"http://172.17.30.172:11434\" #COMPUTACION\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=local_llm, base_url=url_llm, temperature=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea9ef847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import Dict, List, Optional\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "class CSVLoader(BaseLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_path: str,\n",
    "        source_column: Optional[str] = None,\n",
    "        metadata_columns: Optional[List[str]] = None,\n",
    "        csv_args: Optional[Dict] = None,\n",
    "        encoding: Optional[str] = None,\n",
    "    ):\n",
    "        self.file_path = file_path\n",
    "        self.source_column = source_column\n",
    "        self.encoding = encoding\n",
    "        self.csv_args = csv_args or {}\n",
    "        self.metadata_columns = metadata_columns or []\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        docs = []\n",
    "        with open(self.file_path, newline=\"\", encoding=self.encoding) as csvfile:\n",
    "            csv_reader = csv.DictReader(csvfile, **self.csv_args)\n",
    "            for i, row in enumerate(csv_reader):\n",
    "                metadata = {\"row\": i}\n",
    "                for col in self.metadata_columns:\n",
    "                    if col in row:\n",
    "                        metadata[col] = row[col].strip()\n",
    "                content = []\n",
    "                for k, v in row.items():\n",
    "                    if k != self.source_column and k not in self.metadata_columns:\n",
    "                        content.append(f\"{k.strip()}: {v.strip()}\")\n",
    "                doc_content = \"\\n\".join(content)\n",
    "                doc = Document(page_content=doc_content, metadata=metadata)\n",
    "                docs.append(doc)\n",
    "\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18faf2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_columns = [\"row\", \"grant agreement\", \"project acronym\", \"organisation PIC\", \"organisation name\", \"Small or Medium-sized Enterprise\",\n",
    "                   \"organisation activity type\", \"organisation country\", \"organisation role\", \"funding for the organisation\", \n",
    "                    \"organisation total participation cost\", \"project title\", \"project total cost\", \"funding for the project\",\n",
    "                   \"master call\", \"subcall\", \"type of proposal\", \"project legal basis\", \"project topic\"]\n",
    "\n",
    "# Instancia el CSVLoader con el archivo CSV y las columnas de metadatos\n",
    "loader = CSVLoader(\n",
    "    file_path = r\"C:\\Users\\emolt\\OneDrive - UMH\\MASTER\\TFM\\BASE\\cordis_data_processed.csv\",\n",
    "    source_column= None,  # Opcional: columna para establecer como origen\n",
    "    metadata_columns=metadata_columns,\n",
    "    encoding=\"latin1\"\n",
    ")\n",
    "\n",
    "# Carga los documentos del CSV\n",
    "raw_documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44257374",
   "metadata": {},
   "source": [
    "## Exp . 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83d7f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=800)\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf298212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE USA UNA DE LAS GPU\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"all-mpnet-base-v2\"\n",
    "model_kwargs = {\"device\": \"cpu\"} # Al no tener NVIDIA es necesario cambiarlo model_kwargs = {'device': 'cuda:0'}\n",
    "\n",
    "emb = HuggingFaceBgeEmbeddings(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e73cb832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emolt\\AppData\\Local\\Temp\\ipykernel_16444\\3684503522.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore_load = Chroma(persist_directory=\"./chroma_db_7\", embedding_function= emb)\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "vectorstore_load = Chroma(persist_directory=\"./chroma_db_7\", embedding_function= emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f6fbc",
   "metadata": {},
   "source": [
    "## Exp . 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe85684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=400)\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57c3ebfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emolt\\AppData\\Local\\Temp\\ipykernel_12172\\3381727767.py:8: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  emb = HuggingFaceBgeEmbeddings(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs)\n",
      "C:\\Users\\emolt\\anaconda3\\envs\\py310real\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# SE USA UNA DE LAS GPU\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-large-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"} # Al no tener NVIDIA es necesario cambiarlo model_kwargs = {'device': 'cuda:0'}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "\n",
    "emb = HuggingFaceBgeEmbeddings(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a836049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emolt\\AppData\\Local\\Temp\\ipykernel_12172\\181892508.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore_load = Chroma(persist_directory=\"./chroma_db_8\", embedding_function= emb)\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "vectorstore_load = Chroma(persist_directory=\"./chroma_db_8\", embedding_function= emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a9eab",
   "metadata": {},
   "source": [
    "## EXP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f8c399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=800)\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5dcd968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emolt\\AppData\\Local\\Temp\\ipykernel_8492\\3381727767.py:8: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  emb = HuggingFaceBgeEmbeddings(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs)\n",
      "C:\\Users\\emolt\\anaconda3\\envs\\py310real\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# SE USA UNA DE LAS GPU\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-large-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"} # Al no tener NVIDIA es necesario cambiarlo model_kwargs = {'device': 'cuda:0'}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "\n",
    "emb = HuggingFaceBgeEmbeddings(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87e45818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emolt\\AppData\\Local\\Temp\\ipykernel_8492\\3777166952.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore_load = Chroma(persist_directory=\"./chroma_db_9\", embedding_function= emb)\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "vectorstore_load = Chroma(persist_directory=\"./chroma_db_9\", embedding_function= emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3cd213",
   "metadata": {},
   "source": [
    "## EXP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44a1359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cfc6a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emolt\\AppData\\Local\\Temp\\ipykernel_15164\\3381727767.py:8: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  emb = HuggingFaceBgeEmbeddings(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs)\n",
      "C:\\Users\\emolt\\anaconda3\\envs\\py310real\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# SE USA UNA DE LAS GPU\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-large-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"} # Al no tener NVIDIA es necesario cambiarlo model_kwargs = {'device': 'cuda:0'}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "\n",
    "emb = HuggingFaceBgeEmbeddings(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58937ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emolt\\AppData\\Local\\Temp\\ipykernel_15164\\3111488637.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore_load = Chroma(persist_directory=\"./chroma_db_13\", embedding_function= emb)\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "vectorstore_load = Chroma(persist_directory=\"./chroma_db_13\", embedding_function= emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d0a55d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 REAL",
   "language": "python",
   "name": "py310real"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
